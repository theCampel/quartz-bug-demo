A way of mathematically representing a word (often to a [[Neural Network]]). 

There's multiple ways of embedding words:
- [[One-Hot Encoding]]
- [[Vector Embeddings]]

> [!note] Interesting Note
> Also consider the vitality of having word embeddings. If you tried feeding it characters (where each character had a digit encoding), the neural net would first have to learn the relationships between characters, then in turn individual words before it could learn anything of use about the relationships between the words.

