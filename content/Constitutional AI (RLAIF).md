## What:
Imagine taking [[Reinforcement Learning from Human Feedback (RLHF)|RLHF]] and the reward model this time is based on an [[AI|off-the-shelf-LLM]] following a bunch of rules (a constitution). 